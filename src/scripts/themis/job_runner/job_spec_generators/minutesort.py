#!/usr/bin/env python

import sys, argparse, utils, json, getpass

def minutesort(hdfs, username, graysort_format, **kwargs):
    job_name = "Graysort"
    if not graysort_format:
        job_name = "Graysort-MapReduceHeaders"

    input_dir = "%s/inputs/%s" % (username, job_name)

    config = utils.mapreduce_job(
        input_dir, job_name, username, hdfs,
        partition_function = "UniformPartitionFunction")

    params = {
        "SKIP_PHASE_ZERO": 1,
        "SKIP_PHASE_TWO": 1,
        "USE_WRITE_CHAINING": 0,
        "WORKER_IMPLS.phase_one.sorter": "Sorter",
        "WORKER_IMPLS.phase_one.reducer": "Reducer",
        "ALIGNMENT.phase_one.sorter": 0,
        "ALIGNMENT.phase_one.reducer": 0
    }

    if graysort_format:
        params["WRITE_WITHOUT_HEADERS.phase_one"] = 1
        params["MAP_INPUT_FORMAT_READER"] = "FixedSizeKVPairFormatReader"
        params["MAP_INPUT_FIXED_KEY_LENGTH"] = 10
        params["MAP_INPUT_FIXED_VALUE_LENGTH"] =  90
        params["REDUCE_INPUT_FIXED_KEY_LENGTH"] = 10
        params["REDUCE_INPUT_FIXED_VALUE_LENGTH"] =  90

    if "params" not in config:
        config["params"] = {}

    for key, value in params.items():
        config["params"][key] = value

    return config

def main():
    parser = argparse.ArgumentParser(
        description="generates a job spec file for minute-sorting data that "
        "has been generated by generateGraysortInputs.py")
    parser.add_argument("--hdfs", help="host:port specifying the HDFS namenode "
                        "where input and output data should be stored "
                        "(default: store data on local disks rather than on "
                        "HDFS)")
    parser.add_argument("-o", "--output_filename", help="name of the job "
                        "spec file to write (default: %(default)s)",
                        default="minutesort.json")
    parser.add_argument("-u", "--username", help="the username on whose data "
                        "the job is being run", default=getpass.getuser())
    parser.add_argument("-g", "--graysort_format", default=False,
                        action="store_true",
                        help="Run in 'graysort compatibility mode' and don't "
                        "store mapreduce tuple headers in input, intermedaite,"
                        "or output data sets")

    args = parser.parse_args()

    config = minutesort(**vars(args))

    with open(args.output_filename, 'w') as fp:
        json.dump(config, fp, indent=2)

if __name__ == "__main__":
    sys.exit(main())
